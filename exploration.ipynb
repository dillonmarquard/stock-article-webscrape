{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d15984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawler import APIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251aa268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chrome Webscraper <selenium.webdriver.chrome.webdriver.WebDriver (session=\"77eeaae4c337f36523cd0c8ace628cd3\")> (C:\\Users\\dmarq\\.wdm\\drivers\\chromedriver\\win32\\113.0.5672.63\\chromedriver.exe)\n"
     ]
    }
   ],
   "source": [
    "api = APIClient()\n",
    "print(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdata = api.get_stock_data('tsla','2023-03-14',25,progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b2f83c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class apiThreadSlave(threading.Thread):\n",
    "   def __init__(self, thread_id, tag, dates, num_links):\n",
    "      threading.Thread.__init__(self)\n",
    "      self.thread_id = thread_id\n",
    "      self.tag = tag\n",
    "      self.dates = dates\n",
    "      self.num_links = num_links\n",
    "      self.api = APIClient()\n",
    "   def run(self):\n",
    "      for i, date in enumerate(self.dates):\n",
    "         tmpdata = self.api.get_stock_data(self.tag, date,self.num_links)\n",
    "         if tmpdata.shape[0] > 0:\n",
    "            tmpdata.to_csv(r'data/{}/{}.csv'.format(self.tag,date),index=False)\n",
    "            print('Thread ID:',self.thread_id,'Link #',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c889e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: MaxRecursionError https://twitter.com/IASJ_org/status/1555289985506582528\n",
      "Thread ID: 0 Link # 0\n",
      "Error: MaxRecursionError https://www.futurecar.com/tag/Tesla\n",
      "Thread ID: 2 Link # 0\n",
      "Thread ID: 1 Link # 0\n",
      "Error: MaxRecursionError https://twitter.com/Tesla/status/1602789357156536321\n",
      "Error: MaxRecursionError https://www.futurecar.com/tag/Tesla\n",
      "Error: MaxRecursionError https://twitter.com/ClaraJeffery/status/1604889364978225152\n",
      "Error: MaxRecursionError https://www.teslaworkerrights.org/press.html\n",
      "Thread ID: 3 Link # 0\n",
      "Thread ID: 0 Link # 1\n",
      "Thread ID: 4 Link # 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmarq\\miniconda3\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread ID: 2 Link # 1\n",
      "Error: MaxRecursionError https://investorplace.com/2022/02/google\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmarq\\miniconda3\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: MaxRecursionError https://www.travis.af.mil/SiteMap.aspx\n",
      "Error: MaxRecursionError https://beta.unpri.org/system/files/supporting-materials/2022-07/22-07-12%20Proxy%20Alert%20-%20Tesla.docx\n",
      "Thread ID: 5 Link # 0\n",
      "Thread ID: 4 Link # 1\n",
      "Thread ID: 3 Link # 1\n",
      "Thread ID: 7 Link # 0\n",
      "Thread ID: 2 Link # 2\n",
      "Thread ID: 8 Link # 0\n",
      "Error: MaxRecursionError https://twitter.com/tsrandall/status/1592191807592402944?lang=en\n",
      "Error: MaxRecursionError https://eue.walz-offenburg.de/indiana-busted-newspaper.html\n",
      "Thread ID: 1 Link # 1\n",
      "Thread ID: 6 Link # 0\n",
      "Error: MaxRecursionError https://www.teslaworkerrights.org/press.html\n",
      "Thread ID: 4 Link # 2\n",
      "Thread ID: 3 Link # 2\n",
      "Error: MaxRecursionError https://www.nanovest.io/en/us-stocks/tsla/\n",
      "Thread ID: 9 Link # 0\n",
      "Error: MaxRecursionError https://www.futurecar.com/tag/%20China\n",
      "Error: MaxRecursionError https://mobile.twitter.com/ashleygjovik/status/1511598701210337280\n",
      "Thread ID: 0 Link # 2\n",
      "Error: MaxRecursionError https://www.teslaworkerrights.org/press.html\n",
      "Thread ID: 10 Link # 0\n",
      "Error: MaxRecursionError https://cnevpost.com/2022/11/14/tesla-driver-speaks-after-crash/\n",
      "Thread ID: 7 Link # 1\n",
      "Thread ID: 5 Link # 1\n",
      "Error: MaxRecursionError https://www.israelhayom.com/2022/04/05/tesla-owner-elon-musk-becomes-twitters-biggest-stakeholder/\n",
      "Thread ID: 11 Link # 0\n",
      "Thread ID: 12 Link # 0\n",
      "Error: MaxRecursionError https://twitter.com/SawyerMerritt/status/1524254013025357824?lang=en\n",
      "Thread ID: 6 Link # 1\n",
      "Thread ID: 1 Link # 2\n",
      "Thread ID: 2 Link # 3\n",
      "Thread ID: 4 Link # 3\n",
      "Error: MaxRecursionError https://www.wholesaledoorparts.com/elon-musk-hints-at-tesla-model-y-with-falcon-ff-37222794\n",
      "Error: MaxRecursionError https://www.wholesaledoorparts.com/white-tesla-model-x-with-falcon-wing-doors-open-ff-47907892\n",
      "Thread ID: 9 Link # 1\n",
      "Error: MaxRecursionError https://www.ewfpro.com/index.php/en/component/tags/tag/157-indeks-nasdaq?start=60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmarq\\miniconda3\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: MaxRecursionError https://www.teslaworkerrights.org/press.html\n",
      "Thread ID: 0 Link # 3\n",
      "Error: MaxRecursionError https://www.teslaworkerrights.org/press.html\n",
      "Thread ID: 7 Link # 2\n",
      "Error: MaxRecursionError https://cnevpost.com/2022/04/16/teslas-shanghai-plant-will-enter-closed-loop-production-on-april-17-report-says/\n",
      "Thread ID: 10 Link # 1\n",
      "Thread ID: 8 Link # 1\n",
      "Error: MaxRecursionError https://www.travis.af.mil/SiteMap.aspx\n",
      "Thread ID: 5 Link # 2\n",
      "Thread ID: 3 Link # 3\n",
      "Error: MaxRecursionError https://www.wholesaledoorparts.com/2018-tesla-model-x-100d-specifications-ff-47908311\n",
      "Thread ID: 2 Link # 4\n",
      "Thread ID: 12 Link # 1\n",
      "Error: MaxRecursionError https://fgijmyhxl.unifax.pl/\n",
      "Error: MaxRecursionError https://blogs.gartner.com/avivah-litan/2022/04/13/tesla-gets-7-8m-in-real-estate-financing-using-makerdao-real-world-assets-meet-defi/\n",
      "Thread ID: 6 Link # 2\n",
      "Error: MaxRecursionError https://twitter.com/SawyerMerritt/status/1487244771206832130?lang=en\n",
      "Thread ID: 0 Link # 4\n",
      "Error: MaxRecursionError https://cnevpost.com/2022/09/14/nev-insurance-registrations-in-china-for-2nd-week-of-sept/\n",
      "Error: MaxRecursionError https://cnevpost.com/2022/12/05/tesla-sells-record-100291-china-made-vehicles-in-nov/\n",
      "Thread ID: 9 Link # 2\n",
      "Thread ID: 1 Link # 3\n",
      "Thread ID: 10 Link # 2\n",
      "Error: MaxRecursionError https://cnevpost.com/2022/08/18/tesla-shortens-wait-times-for-all-available-models-in-china/\n",
      "Thread ID: 4 Link # 4\n",
      "Thread ID: 7 Link # 3\n",
      "Error: MaxRecursionError https://cnevpost.com/2022/11/15/most-tesla-models-see-shorter-wait-times-in-china/\n",
      "Error: MaxRecursionError https://m.futurecar.com/5621/Tesla-Sells-100291-China-Built-Vehicles-in-November-a-Record-High\n",
      "Error: MaxRecursionError https://cnevpost.com/2022/11/15/china-nev-insurance-registrations-in-2nd-week-of-nov/\n",
      "Thread ID: 11 Link # 1\n"
     ]
    }
   ],
   "source": [
    "#@title Multithreading\n",
    "MAX_THREADS = 12\n",
    "TAG = 'tsla'\n",
    "\n",
    "dt_rng = pd.date_range(start=\"2022-01-01\", end=\"2022-12-31\").date\n",
    "if os.listdir(f'data/{TAG}/') != []: # dont re-scrape dates already scraped for the given TAG\n",
    "    dt_rng = list(set(dt_rng) - set(pd.to_datetime([x[0:-4] for x in os.listdir(f'data/{TAG}/')]).date))\n",
    "# doesnt repeat days already done\n",
    "n = len(dt_rng) // MAX_THREADS # number of dates per thread\n",
    "thread_dt_rng = [dt_rng[x * n:(x + 1) * n] for x in range((len(dt_rng) + n - 1) // n )]\n",
    "\n",
    "threads = [] \n",
    "\n",
    "for i, dates in enumerate(thread_dt_rng):\n",
    "    tmp_thread = apiThreadSlave(i, TAG, dates, 50)\n",
    "    tmp_thread.start()\n",
    "    threads.append(tmp_thread)\n",
    "    time.sleep(15) # wait 15 seconds between spawning threads to prevent google search throttling\n",
    "\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in os.listdir('data/tsla/'):\n",
    "#     f = pd.read_csv(f'data/tsla/{c}')\n",
    "#     f.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "#     f.to_csv(f'data/tsla/{c}',index=False)\n",
    "# fixed the save index error from legacy run to normalize data format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "251455e4",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0d7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://www.bloomberg.com/news/articles/2023-02-17/summers-says-too-soon-to-call-for-march-50-basis-point-fed-hike?srnd=premium\"\n",
    "#url = \"https://www.bloomberg.com/news/articles/2023-02-18/cars-tires-textile-factories-have-shut-in-crisis-hit-pakistan?srnd=industries-v2\"\n",
    "\n",
    "testlinks = api.get_google_links('tsla','2022-02-01',25)\n",
    "testlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = api.get_article_data(testlinks[4])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = api.get_html_from_url(testlinks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22635367",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "text = ''\n",
    "for tmp in [tmp.text for tmp in soup.find_all(['a','p','h','h1','h2'])]:\n",
    "    if len(tmp) > 25 and re.findall('Click here',tmp) == [] and re.findall('This Simple Trick',tmp) == []:\n",
    "        text += tmp + ' '\n",
    "text = re.sub('\\s+',' ',text.replace('\\n',' ').replace('\\xa0',' ').replace('\\'','â€™').replace('   ',' ').strip())\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b57d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "09a439d790eceb95925da18f74694a4b3c4d77bfcf6c49a15526c21ab323f951"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
