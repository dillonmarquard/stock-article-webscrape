{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d15984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawler import APIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251aa268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chrome Webscraper <selenium.webdriver.chrome.webdriver.WebDriver (session=\"71506a74776e314e53987a3117d0ee5f\")> (C:\\Users\\dmarq\\.wdm\\drivers\\chromedriver\\win32\\113.0.5672.63\\chromedriver.exe)\n"
     ]
    }
   ],
   "source": [
    "api = APIClient()\n",
    "print(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d9e082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 8/27 [00:11<00:51,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: MaxRecursionError https://fingfx.thomsonreuters.com/gfx/legaldocs/mypmobmbwpr/Lambrix%20v%20Tesla%20-%20ND%20California%20-%202023-03-14.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:19<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "tmpdata = api.get_stock_data('tsla','2023-03-14',25,progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2f83c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class apiThreadSlave(threading.Thread):\n",
    "   def __init__(self, thread_id, tag, dates, num_links):\n",
    "      threading.Thread.__init__(self)\n",
    "      self.thread_id = thread_id\n",
    "      self.tag = tag\n",
    "      self.dates = dates\n",
    "      self.num_links = num_links\n",
    "      self.api = APIClient()\n",
    "   def run(self):\n",
    "      for i, date in enumerate(self.dates):\n",
    "         tmpdata = self.api.get_stock_data(self.tag, date,self.num_links)\n",
    "         if tmpdata.shape[0] > 0:\n",
    "            tmpdata.to_csv(r'data/{}/{}.csv'.format(self.tag,date),index=False)\n",
    "            print('Thread ID:',self.thread_id,'Link #',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c889e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Multithreading\n",
    "MAX_THREADS = 64\n",
    "TAG = 'tsla'\n",
    "\n",
    "dt_rng = pd.date_range(start=\"2022-01-01\", end=\"2022-12-31\").date\n",
    "if os.listdir(f'data/{TAG}/') != []: # dont re-scrape dates already scraped for the given TAG\n",
    "    dt_rng = set(dt_rng) - set(pd.to_datetime([x[0:-4] for x in os.listdir(f'data/{TAG}/')]).date)\n",
    "# doesnt repeat days already done\n",
    "n = len(dt_rng) // MAX_THREADS # number of dates per thread\n",
    "thread_dt_rng = [dt_rng[x * n:(x + 1) * n] for x in range((len(dt_rng) + n - 1) // n )]\n",
    "\n",
    "threads = []\n",
    "\n",
    "for i, dates in enumerate(thread_dt_rng):\n",
    "    tmp_thread = apiThreadSlave(i, TAG, dates, 50)\n",
    "    tmp_thread.start()\n",
    "    threads.append(tmp_thread)\n",
    "    time.sleep(15) # wait 15 seconds between spawning threads to prevent google search throttling\n",
    "\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in os.listdir('data/tsla/'):\n",
    "#     f = pd.read_csv(f'data/tsla/{c}')\n",
    "#     f.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "#     f.to_csv(f'data/tsla/{c}',index=False)\n",
    "# fixed the save index error from legacy run to normalize data format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "251455e4",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0d7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://www.bloomberg.com/news/articles/2023-02-17/summers-says-too-soon-to-call-for-march-50-basis-point-fed-hike?srnd=premium\"\n",
    "#url = \"https://www.bloomberg.com/news/articles/2023-02-18/cars-tires-textile-factories-have-shut-in-crisis-hit-pakistan?srnd=industries-v2\"\n",
    "\n",
    "testlinks = api.get_google_links('tsla','2022-02-01',25)\n",
    "testlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = api.get_article_data(testlinks[4])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = api.get_html_from_url(testlinks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22635367",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "text = ''\n",
    "for tmp in [tmp.text for tmp in soup.find_all(['a','p','h','h1','h2'])]:\n",
    "    if len(tmp) > 25 and re.findall('Click here',tmp) == [] and re.findall('This Simple Trick',tmp) == []:\n",
    "        text += tmp + ' '\n",
    "text = re.sub('\\s+',' ',text.replace('\\n',' ').replace('\\xa0',' ').replace('\\'','’').replace('   ',' ').strip())\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b57d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "09a439d790eceb95925da18f74694a4b3c4d77bfcf6c49a15526c21ab323f951"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
