{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # visualization\n",
    "import seaborn as sns # visualization\n",
    "# machine learning\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BasicClassifier import BasicClassifier\n",
    "from DataAugment import DataAug\n",
    "from Metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daug = DataAug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets = [\n",
    "    ' [', progressbar.Timer(), '] ',\n",
    "    progressbar.Percentage(), ' ',\n",
    "    progressbar.Bar(),\n",
    "    ' (', progressbar.ETA(), ') ',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mnist dataset\n",
    "dataset = \"MNIST\"\n",
    "BATCH_SIZE = 500\n",
    "num_classes = 10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./data',\n",
    "                               train=True,\n",
    "                               download=True,\n",
    "                               transform=torchvision.transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./data',\n",
    "                               train=False,\n",
    "                               download=True,\n",
    "                               transform=torchvision.transforms.ToTensor()),\n",
    "    batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,test_loader,proportion,funcs,func_proportions,NUM_CLASSSES=10,NUM_EPOCHS=25):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=3e-5)\n",
    "    \n",
    "    epoch_metrics = {}\n",
    "    epoch_test_metrics = {}\n",
    "    \n",
    "    bar = progressbar.ProgressBar(NUM_EPOCHS*len(train_loader),widgets=widgets).start()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.metric.reset_confusion_matrix(NUM_CLASSSES)\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(func_divider(inputs,proportion,funcs,func_proportions).to(device))\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # statistics\n",
    "            model.metric.update_confusion_matrix(outputs.to('cpu'),labels)\n",
    "            # progressbar\n",
    "            bar.update(epoch*len(train_loader)+i)\n",
    "        epoch_metrics[epoch] = model.metric.classification_metrics()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.metric.reset_confusion_matrix(NUM_CLASSSES)\n",
    "            for (inputs, labels) in test_loader:\n",
    "                outputs = model(datafunc(inputs,proportion).to(device))\n",
    "                # statistics\n",
    "                model.metric.update_confusion_matrix(outputs.to('cpu'),labels)\n",
    "                # progressbar\n",
    "            epoch_test_metrics[epoch] = model.metric.classification_metrics()\n",
    "            \n",
    "    return (epoch_metrics,epoch_test_metrics)\n",
    "\n",
    "def func_divider(inputs,proportion,funcs,func_proportions):\n",
    "    func_num = np.ceil(func_proportions*inputs.shape[0]).astype(int)\n",
    "    lossyinputs = torch.clone(inputs)\n",
    "    h = 0\n",
    "    t = 0\n",
    "    for i, func in enumerate(funcs):\n",
    "        t += func_num[i]\n",
    "        lossyinputs[h:t] = funcs[func](lossyinputs[h:t],proportion)\n",
    "        h += t\n",
    "    return lossyinputs\n",
    "    \n",
    "def display_training_metrics(name,epoch_metrics):\n",
    "    sns.lineplot(x=list(epoch_metrics.keys()),y=np.array(list(epoch_metrics.values()),dtype=float)[:,1]) # precision\n",
    "    sns.lineplot(x=list(epoch_metrics.keys()),y=np.array(list(epoch_metrics.values()),dtype=float)[:,2]) # recall\n",
    "    sns.lineplot(x=list(epoch_metrics.keys()),y=np.array(list(epoch_metrics.values()),dtype=float)[:,0],) # accuracy\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title(name)\n",
    "    \n",
    "def display_testing_metrics(name,epoch_metrics):\n",
    "    sns.lineplot(x=list(epoch_metrics.keys()),y=np.array(list(epoch_metrics.values()),dtype=float)[:,1]) # precision\n",
    "    sns.lineplot(x=list(epoch_metrics.keys()),y=np.array(list(epoch_metrics.values()),dtype=float)[:,2]) # recall\n",
    "    sns.lineplot(x=list(epoch_metrics.keys()),y=np.array(list(epoch_metrics.values()),dtype=float)[:,0],) # accuracy\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlabel('% loss')\n",
    "    plt.title(name)\n",
    "    \n",
    "def display_testing_metrics_hist(name,metrics):\n",
    "    sns.barplot(x=['accuracy','precision','recall'],y=metrics[0:3])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_dict = {'rand_pixel':getattr(daug, 'rand_pixel'),\n",
    "             'rand_row':getattr(daug, 'rand_row'),\n",
    "             'rand_column':getattr(daug, 'rand_column'),\n",
    "             'rand_rowcol':getattr(daug, 'rand_rowcol'),\n",
    "             'rand_block':getattr(daug, 'rand_rowcol'),\n",
    "             'pattern_checkerboard':getattr(daug,'pattern_checkerboard'),\n",
    "             'pattern_column':getattr(daug,'pattern_column'),\n",
    "             'pattern_row':getattr(daug,'pattern_row')}\n",
    "\n",
    "proportion = 0.5\n",
    "funcs = {'rand_row':getattr(daug, 'rand_row'),\n",
    "             'rand_column':getattr(daug, 'rand_column')}\n",
    "\n",
    "func_proportions = np.array([0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicClassifier(num_classes)\n",
    "model.to(device)\n",
    "(train_metrics,test_metrics) = train(model,train_loader,test_loader,proportion,funcs,func_proportions,NUM_CLASSSES=num_classes,NUM_EPOCHS=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
